# Shopiet Application Logstash Pipeline Configuration

input {
  # Django application logs from file
  file {
    path => "/app/logs/*.log"
    start_position => "beginning"
    codec => "json"
    tags => ["django", "application"]
    type => "django-app"
  }

  # Django application logs from Docker logs
  file {
    path => "/var/log/containers/*backend*.log"
    start_position => "beginning"
    codec => "json"
    tags => ["django", "container"]
    type => "django-container"
  }

  # Nginx access logs
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    tags => ["nginx", "access"]
    type => "nginx-access"
  }

  # Nginx error logs
  file {
    path => "/var/log/nginx/error.log"
    start_position => "beginning"
    tags => ["nginx", "error"]
    type => "nginx-error"
  }

  # Beats input for external log shippers
  beats {
    port => 5044
    tags => ["beats"]
  }

  # Syslog input for system logs
  syslog {
    port => 5514
    tags => ["syslog"]
  }

  # HTTP input for webhook logs
  http {
    port => 8080
    tags => ["http", "webhook"]
  }
}

filter {
  # Process Django application logs
  if [type] == "django-app" {
    # Parse Django log format
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:message}" 
      }
      overwrite => [ "message" ]
    }

    # Parse JSON if present
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "parsed"
      }
    }

    # Add application-specific fields
    mutate {
      add_field => { 
        "application" => "shopiet"
        "component" => "backend"
        "environment" => "%{ENVIRONMENT}"
      }
    }

    # Parse OpenTelemetry trace fields if present
    if [parsed][trace_id] {
      mutate {
        add_field => { 
          "trace_id" => "%{[parsed][trace_id]}"
          "span_id" => "%{[parsed][span_id]}"
        }
      }
    }

    # Parse user context
    if [parsed][user_id] {
      mutate {
        add_field => { "user_id" => "%{[parsed][user_id]}" }
      }
    }

    # Parse request context
    if [parsed][request_id] {
      mutate {
        add_field => { "request_id" => "%{[parsed][request_id]}" }
      }
    }
  }

  # Process Nginx access logs
  if [type] == "nginx-access" {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}" 
      }
    }

    # Convert response time to number
    if [response_time] {
      mutate {
        convert => { "response_time" => "float" }
      }
    }

    # Add Nginx-specific fields
    mutate {
      add_field => { 
        "application" => "shopiet"
        "component" => "nginx"
        "log_type" => "access"
      }
    }

    # GeoIP lookup for client IP
    geoip {
      source => "clientip"
      target => "geoip"
    }

    # User agent parsing
    useragent {
      source => "agent"
      target => "user_agent"
    }
  }

  # Process Nginx error logs
  if [type] == "nginx-error" {
    grok {
      match => { 
        "message" => "(?<timestamp>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) \[%{LOGLEVEL:level}\] %{POSINT:pid}#%{NUMBER:tid}: (\*%{NUMBER:connection_id} )?%{GREEDYDATA:message}" 
      }
      overwrite => [ "message" ]
    }

    mutate {
      add_field => { 
        "application" => "shopiet"
        "component" => "nginx"
        "log_type" => "error"
      }
    }
  }

  # Process container logs
  if [type] == "django-container" {
    # Parse Docker log format
    json {
      source => "message"
    }

    mutate {
      add_field => { 
        "application" => "shopiet"
        "component" => "backend"
        "source" => "container"
      }
    }
  }

  # Common processing for all logs
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss,SSS", "yyyy/MM/dd HH:mm:ss" ]
    target => "@timestamp"
  }

  # Remove sensitive information
  mutate {
    remove_field => [ "password", "secret", "token", "key" ]
  }

  # Add hostname
  mutate {
    add_field => { "hostname" => "%{HOSTNAME}" }
  }

  # Tag based on log level
  if [level] == "ERROR" or [level] == "CRITICAL" {
    mutate {
      add_tag => [ "error" ]
    }
  }

  if [level] == "WARNING" or [level] == "WARN" {
    mutate {
      add_tag => [ "warning" ]
    }
  }

  # Add correlation ID for request tracking
  if ![correlation_id] and [request_id] {
    mutate {
      add_field => { "correlation_id" => "%{request_id}" }
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "shopiet-logs-%{+YYYY.MM.dd}"
    
    # Use document type based on log type
    template_name => "shopiet-logs"
    template => "/usr/share/logstash/templates/shopiet-template.json"
    template_overwrite => true
    
    # Add metadata
    document_type => "%{type}"
  }

  # Debug output for development
  if [environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }

  # Send errors to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "shopiet-errors-%{+YYYY.MM.dd}"
    }
  }

  # Send metrics to file for Prometheus scraping
  if [component] == "backend" and [parsed][metrics] {
    file {
      path => "/usr/share/logstash/data/metrics.log"
      codec => json
    }
  }

  # Send alerts to external systems (optional)
  if [level] == "CRITICAL" {
    # Uncomment and configure for your alerting system
    # http {
    #   url => "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
    #   http_method => "post"
    #   format => "json"
    #   mapping => {
    #     "text" => "Critical error in Shopiet: %{message}"
    #   }
    # }
  }
}
